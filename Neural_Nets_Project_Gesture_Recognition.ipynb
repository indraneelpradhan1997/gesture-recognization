{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Neural_Nets_Project_Gesture_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-SN4VmUry8J"
      },
      "source": [
        "# **Hand Gesture Recognition**\n",
        "### **Anurag Bombarde**\n",
        "### **Puja Kumari**\n",
        "\n",
        "\n",
        "### **Project has  3D Conv models and Conv2D + RNN (GRU) models**\n",
        "\n",
        "The objective of this projects is to build a hand gesture recognition model that can be hosted on a camera installed in a smart TV that can understand 5 gestures. Namely, leftwards hand movement to go to previous channel, rightward hand movement to go to next channel, upward hand movement to increase the volume, downward hand movement to decrease the volume and a palm gesture to pause playing the video.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmIuIPoumj7O",
        "outputId": "848d8747-35f1-4d3a-9b6e-3f83864dc697"
      },
      "source": [
        "#Checking the GPU Information\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 20 09:02:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZlj28Bct3nF",
        "outputId": "32e5a45c-4f78-4e85-aa11-56ba074256b1"
      },
      "source": [
        "pip install scipy==1.2.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.2.1\n",
            "  Downloading scipy-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.1) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivE6QecJry8P"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from scipy.misc.pilutil import imread\n",
        "from scipy.misc import imread, imresize\n",
        "import datetime\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ4tCuBHry8S"
      },
      "source": [
        "Setting the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CkCW-rEry8S"
      },
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.set_random_seed(30)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9En1mFdRXE2"
      },
      "source": [
        "Unzipped data into the GDrive and reading from it by mounting it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL0QMXWIvNIk",
        "outputId": "f530d026-0ff3-4dc3-b809-1bbebc8a724f"
      },
      "source": [
        "# open('sample_data/README.md').readlines()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Z-S9f4B0sC",
        "outputId": "fc2f85d6-39cb-40bd-fc3d-79946cf707f2"
      },
      "source": [
        "ls \"/content/drive/MyDrive/Project_data/Project_data/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mtrain\u001b[0m/  train.csv  \u001b[01;34mval\u001b[0m/  val.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHGpG9l3ry8T"
      },
      "source": [
        "Reading the folder names for training and validation. Also setting the `batch_size` here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b12Oeh3-ry8T"
      },
      "source": [
        "\n",
        "\n",
        "train_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/Project_data/val.csv').readlines())\n",
        "batch_size = 64 #Tried with batch size of 10 and 50 , it takes too long to execute 10 batchsize"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7YfRoPwry8U"
      },
      "source": [
        "## Generator\n",
        "In the generator, going to preprocess the images as images are of 2 different dimensions as well as creating a batch of video frames. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbT53aClvWoG"
      },
      "source": [
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    # print('folder_list=',folder_list)\n",
        "    #List of images using image indexes as below to use for the sequence \n",
        "    img_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(t)/batch_size)\n",
        "        #Iterating over number of batches\n",
        "        for batch in range(num_batches):\n",
        "            # 18 as per img_idx is the number of images used for each video, (x,y) = (84,84) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_data = np.zeros((batch_size,18,84,84,3))\n",
        "            # one hot representation of the output\n",
        "            batch_labels = np.zeros((batch_size,5))\n",
        "            # iterating over the batch_size\n",
        "            for folder in range(batch_size):\n",
        "                # read all the images in the folder\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0])\n",
        "                #  Iterating over the frames/images of a folder to read them in\n",
        "                for idx,item in enumerate(img_idx):\n",
        "\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    #cropping the images and resizing them. Note that the images are of 2 different shape \n",
        "                    image = imresize(image,(84,84)).astype(np.float32)\n",
        "                    #normalising using min/max normalization and feeding in the image\n",
        "                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.min(image[:,:,0]))/(np.max(image[:,:,0])- np.min(image[:,:,0])) \n",
        "                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.min(image[:,:,1]))/(np.max(image[:,:,1])- np.min(image[:,:,1])) \n",
        "                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.min(image[:,:,2]))/(np.max(image[:,:,2])- np.min(image[:,:,2])) \n",
        "                    \n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels\n",
        "        # Below code is for remaining data points which are left after full batches\n",
        "        if (len(t)%batch_size) != 0:\n",
        "            batch_data = np.zeros((len(t)%batch_size,18,84,84,3))\n",
        "            batch_labels = np.zeros((len(t)%batch_size,5))\n",
        "            for folder in range(len(t)%batch_size):\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0])\n",
        "                for idx,item in enumerate(img_idx):\n",
        "                    image = imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #cropping the images and resizing them. Note that the images are of 2 different shape \n",
        "                    image = imresize(image,(84,84)).astype(np.float32)\n",
        "                    #normalising using min/max normalization and feeding in the image\n",
        "                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.min(image[:,:,0]))/(np.max(image[:,:,0])- np.min(image[:,:,0]))\n",
        "                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.min(image[:,:,1]))/(np.max(image[:,:,1])- np.min(image[:,:,1]))\n",
        "                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.min(image[:,:,2]))/(np.max(image[:,:,2])- np.min(image[:,:,2]))\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
        "\n",
        "            yield batch_data, batch_labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtPtTnpiry8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39eec41-c92e-436f-bb68-1d26caf76dfb"
      },
      "source": [
        "#Date time to save models with timestamp as experimenting with multiple models\n",
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/drive/MyDrive/Project_data/Project_data/train'\n",
        "val_path = '/content/drive/MyDrive/Project_data/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "#Choosing epochs as 30 \n",
        "num_epochs = 30\n",
        "print ('# epochs =', num_epochs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHRQKK47ry8Y"
      },
      "source": [
        "## Model\n",
        "Creating 2 models using different functionalities that Keras provides those are Conv3D and Conv2D+RNN(GRU). Using `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. Using `TimeDistributed` while building a Conv2D + RNN model. Last layer is the softmax. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djB58H5kWTNQ"
      },
      "source": [
        "\n",
        "*** Architecture 1 ***. **Convolution 3D Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5uvSo30vj9Z"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Dropout, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "###**** Model 1***##\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
        "\n",
        "# model.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "##******************** With above model and adam optimizer below is the result\n",
        "### ******.  Total params: 1,838,565\n",
        "### *******. Trainable params: 1,838,181\n",
        "#### ******.  Non-trainable params: 38 ********###\n",
        "#### ***** Not performing good as below result is coming as best possible model with categorical/training accuracy as 64% and validation accuracy as 18%\n",
        "# Epoch 28/30\n",
        "# 11/11 [==============================] - 70s 7s/step - loss: 0.9562 - categorical_accuracy: 0.6425 - val_loss: 2.6069 - val_categorical_accuracy: 0.1800\n",
        "\n",
        "# Epoch 00028: saving model to model_init_2021-10-1910_58_01.860195/model-00028-0.95618-0.64253-2.60688-0.18000.h5\n",
        "\n",
        "### Hence experimenting with another model as below ##\n",
        "\n",
        "\n",
        "###**** Model 2***##\n",
        "nb_featuremap = [8,16,32,64]\n",
        "nb_dense = [128,64,5]\n",
        "nb_classes = 5\n",
        "Input_shape = (18,84,84,3)\n",
        "model = Sequential()\n",
        "model.add(Conv3D(nb_featuremap[0], \n",
        "                 kernel_size=(5,5,5),\n",
        "                 input_shape=Input_shape,\n",
        "                 padding='same', name=\"conv1\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv3D(nb_featuremap[1], \n",
        "                 kernel_size=(3,3,3),\n",
        "                 padding='same',name=\"conv2\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Conv3D(nb_featuremap[2], \n",
        "                 kernel_size=(1,3,3), \n",
        "                 padding='same',name=\"conv3\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(nb_dense[0], activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(nb_dense[1], activation='relu'))\n",
        "#softmax layer\n",
        "model.add(Dense(nb_dense[2], activation='softmax'))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb5ZfgaWry8Z"
      },
      "source": [
        "Compiling and printing model summary for Conv3D model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "J-NSB45-ry8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1b82c8-af33-4620-d125-1cc777d5fd9b"
      },
      "source": [
        "\n",
        "#Using adam optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv3D)               (None, 18, 84, 84, 8)     3008      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 18, 84, 84, 8)     0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv3D)               (None, 18, 84, 84, 16)    3472      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 18, 84, 84, 16)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 9, 42, 42, 16)     0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv3D)               (None, 9, 42, 42, 32)     4640      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 9, 42, 42, 32)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 4, 21, 21, 32)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 21, 21, 32)     128       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 21, 21, 32)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 2, 10, 10, 32)     0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               819328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 839,157\n",
            "Trainable params: 839,093\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwNy2aE8ry8a"
      },
      "source": [
        "Creating the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRXBvvJury8a"
      },
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLR5mzz5ry8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68176e97-7a2a-4ab8-f9d9-63e69113b7b4"
      },
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "        \n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJh4VnZFry8b"
      },
      "source": [
        "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQyC9Tvry8b"
      },
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByAr1hs9ry8c"
      },
      "source": [
        "Fitting the model. This will start training the model and with the help of the checkpoints, it will save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMGn9Sp9ry8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97139fb4-7f0b-4e16-ea4f-4713515df5bf"
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source path =  /content/drive/MyDrive/Project_data/Project_data/train ; batch size = 64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/11 [==========================>...] - ETA: 5:33 - loss: 2.1256 - categorical_accuracy: 0.2172 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - ETA: 0s - loss: 2.1070 - categorical_accuracy: 0.2187  Source path =  /content/drive/MyDrive/Project_data/Project_data/val ; batch size = 64\n",
            "11/11 [==============================] - 3742s 372s/step - loss: 2.1070 - categorical_accuracy: 0.2187 - val_loss: 1.6159 - val_categorical_accuracy: 0.2200\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-10-2009_02_55.691325/model-00001-2.10697-0.21870-1.61595-0.22000.h5\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.5723 - categorical_accuracy: 0.2489 - val_loss: 1.6488 - val_categorical_accuracy: 0.1700\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-10-2009_02_55.691325/model-00002-1.57226-0.24887-1.64878-0.17000.h5\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.4880 - categorical_accuracy: 0.3379 - val_loss: 1.6013 - val_categorical_accuracy: 0.2000\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-10-2009_02_55.691325/model-00003-1.48804-0.33786-1.60126-0.20000.h5\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.3651 - categorical_accuracy: 0.4374 - val_loss: 1.6009 - val_categorical_accuracy: 0.2200\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-10-2009_02_55.691325/model-00004-1.36510-0.43741-1.60094-0.22000.h5\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.2540 - categorical_accuracy: 0.5038 - val_loss: 1.6437 - val_categorical_accuracy: 0.1700\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-10-2009_02_55.691325/model-00005-1.25399-0.50377-1.64371-0.17000.h5\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.1052 - categorical_accuracy: 0.5973 - val_loss: 1.5723 - val_categorical_accuracy: 0.2500\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-10-2009_02_55.691325/model-00006-1.10519-0.59729-1.57234-0.25000.h5\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.9383 - categorical_accuracy: 0.6244 - val_loss: 1.5427 - val_categorical_accuracy: 0.3200\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-10-2009_02_55.691325/model-00007-0.93832-0.62443-1.54268-0.32000.h5\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 0.7836 - categorical_accuracy: 0.7119 - val_loss: 1.5690 - val_categorical_accuracy: 0.3000\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-10-2009_02_55.691325/model-00008-0.78364-0.71192-1.56902-0.30000.h5\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.5718 - categorical_accuracy: 0.7858 - val_loss: 1.4758 - val_categorical_accuracy: 0.3600\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-10-2009_02_55.691325/model-00009-0.57181-0.78582-1.47584-0.36000.h5\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.4977 - categorical_accuracy: 0.8130 - val_loss: 1.4548 - val_categorical_accuracy: 0.4000\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-10-2009_02_55.691325/model-00010-0.49770-0.81297-1.45479-0.40000.h5\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.3460 - categorical_accuracy: 0.8763 - val_loss: 1.4073 - val_categorical_accuracy: 0.4000\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-10-2009_02_55.691325/model-00011-0.34604-0.87632-1.40727-0.40000.h5\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 0.2882 - categorical_accuracy: 0.8944 - val_loss: 1.3555 - val_categorical_accuracy: 0.5200\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-10-2009_02_55.691325/model-00012-0.28819-0.89442-1.35548-0.52000.h5\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.2128 - categorical_accuracy: 0.9397 - val_loss: 1.4107 - val_categorical_accuracy: 0.3800\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-10-2009_02_55.691325/model-00013-0.21282-0.93967-1.41072-0.38000.h5\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.1481 - categorical_accuracy: 0.9487 - val_loss: 1.2788 - val_categorical_accuracy: 0.5300\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-10-2009_02_55.691325/model-00014-0.14807-0.94872-1.27880-0.53000.h5\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.1529 - categorical_accuracy: 0.9487 - val_loss: 1.3299 - val_categorical_accuracy: 0.4100\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-10-2009_02_55.691325/model-00015-0.15286-0.94872-1.32987-0.41000.h5\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 0.1481 - categorical_accuracy: 0.9502 - val_loss: 1.2675 - val_categorical_accuracy: 0.4800\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-10-2009_02_55.691325/model-00016-0.14809-0.95023-1.26747-0.48000.h5\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.1087 - categorical_accuracy: 0.9653 - val_loss: 1.3061 - val_categorical_accuracy: 0.4200\n",
            "\n",
            "Epoch 00017: saving model to model_init_2021-10-2009_02_55.691325/model-00017-0.10870-0.96531-1.30612-0.42000.h5\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 0.1141 - categorical_accuracy: 0.9638 - val_loss: 1.1811 - val_categorical_accuracy: 0.4600\n",
            "\n",
            "Epoch 00018: saving model to model_init_2021-10-2009_02_55.691325/model-00018-0.11409-0.96380-1.18108-0.46000.h5\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.1038 - categorical_accuracy: 0.9578 - val_loss: 1.2166 - val_categorical_accuracy: 0.5000\n",
            "\n",
            "Epoch 00019: saving model to model_init_2021-10-2009_02_55.691325/model-00019-0.10379-0.95777-1.21664-0.50000.h5\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.0780 - categorical_accuracy: 0.9759 - val_loss: 1.1772 - val_categorical_accuracy: 0.4700\n",
            "\n",
            "Epoch 00020: saving model to model_init_2021-10-2009_02_55.691325/model-00020-0.07797-0.97587-1.17723-0.47000.h5\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0471 - categorical_accuracy: 0.9879 - val_loss: 1.1977 - val_categorical_accuracy: 0.5500\n",
            "\n",
            "Epoch 00021: saving model to model_init_2021-10-2009_02_55.691325/model-00021-0.04708-0.98793-1.19770-0.55000.h5\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 0.0462 - categorical_accuracy: 0.9804 - val_loss: 1.0588 - val_categorical_accuracy: 0.5500\n",
            "\n",
            "Epoch 00022: saving model to model_init_2021-10-2009_02_55.691325/model-00022-0.04624-0.98039-1.05880-0.55000.h5\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.0417 - categorical_accuracy: 0.9849 - val_loss: 1.1230 - val_categorical_accuracy: 0.5100\n",
            "\n",
            "Epoch 00023: saving model to model_init_2021-10-2009_02_55.691325/model-00023-0.04168-0.98492-1.12303-0.51000.h5\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 64s 6s/step - loss: 0.0724 - categorical_accuracy: 0.9834 - val_loss: 0.9730 - val_categorical_accuracy: 0.6800\n",
            "\n",
            "Epoch 00024: saving model to model_init_2021-10-2009_02_55.691325/model-00024-0.07244-0.98341-0.97301-0.68000.h5\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.0467 - categorical_accuracy: 0.9849 - val_loss: 1.1440 - val_categorical_accuracy: 0.5300\n",
            "\n",
            "Epoch 00025: saving model to model_init_2021-10-2009_02_55.691325/model-00025-0.04672-0.98492-1.14404-0.53000.h5\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.0477 - categorical_accuracy: 0.9864 - val_loss: 1.0471 - val_categorical_accuracy: 0.6200\n",
            "\n",
            "Epoch 00026: saving model to model_init_2021-10-2009_02_55.691325/model-00026-0.04775-0.98643-1.04707-0.62000.h5\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.0295 - categorical_accuracy: 0.9910 - val_loss: 1.2117 - val_categorical_accuracy: 0.4800\n",
            "\n",
            "Epoch 00027: saving model to model_init_2021-10-2009_02_55.691325/model-00027-0.02946-0.99095-1.21168-0.48000.h5\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.0245 - categorical_accuracy: 0.9955 - val_loss: 1.1393 - val_categorical_accuracy: 0.5200\n",
            "\n",
            "Epoch 00028: saving model to model_init_2021-10-2009_02_55.691325/model-00028-0.02451-0.99548-1.13927-0.52000.h5\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0220 - categorical_accuracy: 0.9970 - val_loss: 1.1395 - val_categorical_accuracy: 0.5400\n",
            "\n",
            "Epoch 00029: saving model to model_init_2021-10-2009_02_55.691325/model-00029-0.02200-0.99698-1.13947-0.54000.h5\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 65s 6s/step - loss: 0.0229 - categorical_accuracy: 0.9955 - val_loss: 1.1349 - val_categorical_accuracy: 0.5900\n",
            "\n",
            "Epoch 00030: saving model to model_init_2021-10-2009_02_55.691325/model-00030-0.02292-0.99548-1.13487-0.59000.h5\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86521123d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddx0q9LUtgOu"
      },
      "source": [
        "Looks like model 2 of Conv3D archtecture above is performing good with \n",
        "11/11 [==============================] - 64s 6s/step - loss: 0.0724 - categorical_accuracy: 0.9834 - val_loss: 0.9730 - val_categorical_accuracy: 0.6800\n",
        "\n",
        "i.e training accuracy of 97% and validation accuracy of 68%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW9mIotOXEyW"
      },
      "source": [
        "*** Architecture 2***. **Convolution 2D+GRU Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTKpYIC9Yhni"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, Bidirectional\n",
        "\n",
        "\n",
        "modelGRU = Sequential()\n",
        "modelGRU.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), activation='relu', padding='same'), input_shape=Input_shape))\n",
        "modelGRU.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=\"he_normal\", activation='relu')))\n",
        "modelGRU.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        " \n",
        "modelGRU.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        " \n",
        "modelGRU.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        " \n",
        "modelGRU.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        " \n",
        "modelGRU.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "modelGRU.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        " \n",
        "modelGRU.add(TimeDistributed(Flatten()))\n",
        " \n",
        "modelGRU.add(Dropout(0.5))\n",
        "modelGRU.add(GRU(512, return_sequences=False, dropout=0.5))\n",
        "modelGRU.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4GiXPtWvYWX"
      },
      "source": [
        "Compiling and printing model summary for Conv2D+GRU model 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZILMlmCYlr1c",
        "outputId": "b62d5b33-e1a8-45a2-b0fd-05cb570372e5"
      },
      "source": [
        "modelGRU.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (modelGRU.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 18, 42, 42, 32)    4736      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 18, 40, 40, 32)    9248      \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 18, 20, 20, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 18, 20, 20, 64)    18496     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 18, 20, 20, 64)    36928     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 18, 10, 10, 64)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 18, 10, 10, 128)   73856     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 18, 10, 10, 128)   147584    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 18, 5, 5, 128)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 18, 5, 5, 256)     295168    \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 18, 5, 5, 256)     590080    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 18, 2, 2, 256)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 18, 2, 2, 512)     1180160   \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 18, 2, 2, 512)     2359808   \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 18, 1, 1, 512)     0         \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 18, 512)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 18, 512)           0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 512)               1575936   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 6,294,565\n",
            "Trainable params: 6,294,565\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4HrXtcOvf0M"
      },
      "source": [
        "Fitting GRU Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV5Mt9qJYnHW",
        "outputId": "7114f454-7740-4331-c9ef-02aaca54a878"
      },
      "source": [
        "modelGRU.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 9/11 [=======================>......] - ETA: 8s - loss: 1.6163 - categorical_accuracy: 0.1667 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 64s 6s/step - loss: 1.6146 - categorical_accuracy: 0.1735 - val_loss: 1.6067 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-10-2009_02_55.691325/model-00001-1.61462-0.17345-1.60672-0.23000.h5\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6091 - categorical_accuracy: 0.1916 - val_loss: 1.6084 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-10-2009_02_55.691325/model-00002-1.60910-0.19155-1.60844-0.21000.h5\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 65s 7s/step - loss: 1.6111 - categorical_accuracy: 0.1946 - val_loss: 1.6067 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-10-2009_02_55.691325/model-00003-1.61110-0.19457-1.60670-0.21000.h5\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6101 - categorical_accuracy: 0.2097 - val_loss: 1.6091 - val_categorical_accuracy: 0.1700\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-10-2009_02_55.691325/model-00004-1.61012-0.20965-1.60909-0.17000.h5\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 65s 7s/step - loss: 1.6103 - categorical_accuracy: 0.2051 - val_loss: 1.6067 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-10-2009_02_55.691325/model-00005-1.61033-0.20513-1.60674-0.21000.h5\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 1.6094 - categorical_accuracy: 0.2021 - val_loss: 1.6038 - val_categorical_accuracy: 0.2000\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-10-2009_02_55.691325/model-00006-1.60942-0.20211-1.60380-0.20000.h5\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6080 - categorical_accuracy: 0.2127 - val_loss: 1.6066 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-10-2009_02_55.691325/model-00007-1.60804-0.21267-1.60655-0.21000.h5\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6083 - categorical_accuracy: 0.1795 - val_loss: 1.6011 - val_categorical_accuracy: 0.2400\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-10-2009_02_55.691325/model-00008-1.60829-0.17949-1.60114-0.24000.h5\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 1.6093 - categorical_accuracy: 0.1885 - val_loss: 1.6063 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-10-2009_02_55.691325/model-00009-1.60929-0.18854-1.60632-0.21000.h5\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6090 - categorical_accuracy: 0.2036 - val_loss: 1.6074 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-10-2009_02_55.691325/model-00010-1.60898-0.20362-1.60739-0.21000.h5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6084 - categorical_accuracy: 0.2051 - val_loss: 1.6062 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-10-2009_02_55.691325/model-00011-1.60845-0.20513-1.60620-0.21000.h5\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6083 - categorical_accuracy: 0.2142 - val_loss: 1.6058 - val_categorical_accuracy: 0.2200\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-10-2009_02_55.691325/model-00012-1.60825-0.21418-1.60585-0.22000.h5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 65s 7s/step - loss: 1.6091 - categorical_accuracy: 0.2127 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-10-2009_02_55.691325/model-00013-1.60912-0.21267-1.60609-0.23000.h5\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 1.6089 - categorical_accuracy: 0.2142 - val_loss: 1.6034 - val_categorical_accuracy: 0.4000\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-10-2009_02_55.691325/model-00014-1.60893-0.21418-1.60339-0.40000.h5\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 1.6080 - categorical_accuracy: 0.2368 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-10-2009_02_55.691325/model-00015-1.60802-0.23680-1.60613-0.23000.h5\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6080 - categorical_accuracy: 0.2217 - val_loss: 1.6042 - val_categorical_accuracy: 0.2600\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-10-2009_02_55.691325/model-00016-1.60801-0.22172-1.60415-0.26000.h5\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6099 - categorical_accuracy: 0.1976 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00017: saving model to model_init_2021-10-2009_02_55.691325/model-00017-1.60988-0.19759-1.60612-0.23000.h5\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 1.6073 - categorical_accuracy: 0.2006 - val_loss: 1.6045 - val_categorical_accuracy: 0.2500\n",
            "\n",
            "Epoch 00018: saving model to model_init_2021-10-2009_02_55.691325/model-00018-1.60733-0.20060-1.60450-0.25000.h5\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.6089 - categorical_accuracy: 0.2142 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00019: saving model to model_init_2021-10-2009_02_55.691325/model-00019-1.60893-0.21418-1.60610-0.23000.h5\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 1.6080 - categorical_accuracy: 0.2051 - val_loss: 1.6096 - val_categorical_accuracy: 0.2600\n",
            "\n",
            "Epoch 00020: saving model to model_init_2021-10-2009_02_55.691325/model-00020-1.60799-0.20513-1.60957-0.26000.h5\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6088 - categorical_accuracy: 0.2112 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00021: saving model to model_init_2021-10-2009_02_55.691325/model-00021-1.60876-0.21116-1.60610-0.23000.h5\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 1.6073 - categorical_accuracy: 0.2278 - val_loss: 1.6043 - val_categorical_accuracy: 0.2200\n",
            "\n",
            "Epoch 00022: saving model to model_init_2021-10-2009_02_55.691325/model-00022-1.60727-0.22775-1.60431-0.22000.h5\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 65s 6s/step - loss: 1.6093 - categorical_accuracy: 0.2202 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00023: saving model to model_init_2021-10-2009_02_55.691325/model-00023-1.60931-0.22021-1.60606-0.23000.h5\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 1.6083 - categorical_accuracy: 0.2127 - val_loss: 1.6088 - val_categorical_accuracy: 0.2200\n",
            "\n",
            "Epoch 00024: saving model to model_init_2021-10-2009_02_55.691325/model-00024-1.60835-0.21267-1.60882-0.22000.h5\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 66s 7s/step - loss: 1.6080 - categorical_accuracy: 0.2232 - val_loss: 1.6059 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00025: saving model to model_init_2021-10-2009_02_55.691325/model-00025-1.60802-0.22323-1.60589-0.23000.h5\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 1.6093 - categorical_accuracy: 0.2187 - val_loss: 1.6042 - val_categorical_accuracy: 0.1900\n",
            "\n",
            "Epoch 00026: saving model to model_init_2021-10-2009_02_55.691325/model-00026-1.60927-0.21870-1.60424-0.19000.h5\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6082 - categorical_accuracy: 0.2262 - val_loss: 1.6057 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00027: saving model to model_init_2021-10-2009_02_55.691325/model-00027-1.60821-0.22624-1.60568-0.23000.h5\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 58s 6s/step - loss: 1.6071 - categorical_accuracy: 0.2308 - val_loss: 1.6078 - val_categorical_accuracy: 0.2400\n",
            "\n",
            "Epoch 00028: saving model to model_init_2021-10-2009_02_55.691325/model-00028-1.60710-0.23077-1.60777-0.24000.h5\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.6070 - categorical_accuracy: 0.2247 - val_loss: 1.6050 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00029: saving model to model_init_2021-10-2009_02_55.691325/model-00029-1.60701-0.22474-1.60504-0.23000.h5\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 1.6070 - categorical_accuracy: 0.2127 - val_loss: 1.6068 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00030: saving model to model_init_2021-10-2009_02_55.691325/model-00030-1.60697-0.21267-1.60677-0.21000.h5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f863c5b6190>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUisbIpmqrR2"
      },
      "source": [
        "Looks like above model is not perforning well as validation and training data accuracy is not improving . Hence using another model as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgCz7wyy3iYK",
        "outputId": "6aad5111-39a6-485b-acfb-808766b599ae"
      },
      "source": [
        "modelGRU2 = Sequential()\n",
        "\n",
        "modelGRU2.add(TimeDistributed(Conv2D(nb_featuremap[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=Input_shape))\n",
        "\n",
        "\n",
        "modelGRU2.add(TimeDistributed(Conv2D(nb_featuremap[1], (3,3),padding='same', activation='relu')))\n",
        "modelGRU2.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "modelGRU2.add(TimeDistributed(Conv2D(nb_featuremap[2], (3,3),padding='same', activation='relu')))\n",
        "modelGRU2.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "modelGRU2.add(TimeDistributed(Conv2D(nb_featuremap[3], (2,2),padding='same', activation='relu')))\n",
        "modelGRU2.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "modelGRU2.add(TimeDistributed(BatchNormalization()))\n",
        "modelGRU2.add(Dropout(0.25))\n",
        "\n",
        "modelGRU2.add(TimeDistributed(Flatten()))\n",
        "\n",
        "modelGRU2.add(Dense(nb_dense[0], activation='relu'))\n",
        "modelGRU2.add(Dropout(0.25))\n",
        "modelGRU2.add(Dense(nb_dense[1], activation='relu'))\n",
        "modelGRU2.add(Dropout(0.25))\n",
        "\n",
        "## using GRU as the RNN model along with softmax as our last layer.\n",
        "modelGRU2.add(GRU(128, return_sequences=False))\n",
        "modelGRU2.add(Dense(nb_classes, activation='softmax')) # using Softmax as last layer\n",
        "modelGRU2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (modelGRU2.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_16 (TimeDis (None, 18, 42, 42, 8)     224       \n",
            "_________________________________________________________________\n",
            "time_distributed_17 (TimeDis (None, 18, 42, 42, 16)    1168      \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 18, 21, 21, 16)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_19 (TimeDis (None, 18, 21, 21, 32)    4640      \n",
            "_________________________________________________________________\n",
            "time_distributed_20 (TimeDis (None, 18, 10, 10, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_21 (TimeDis (None, 18, 10, 10, 64)    8256      \n",
            "_________________________________________________________________\n",
            "time_distributed_22 (TimeDis (None, 18, 5, 5, 64)      0         \n",
            "_________________________________________________________________\n",
            "time_distributed_23 (TimeDis (None, 18, 5, 5, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 18, 5, 5, 64)      0         \n",
            "_________________________________________________________________\n",
            "time_distributed_24 (TimeDis (None, 18, 1600)          0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 18, 128)           204928    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 18, 64)            8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 18, 64)            0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 302,869\n",
            "Trainable params: 302,741\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKBy6bVLvmYv"
      },
      "source": [
        "Fitting GRU model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfhBTuCK3-z2",
        "outputId": "eeeb40d2-5827-45c5-d995-391043c850c0"
      },
      "source": [
        "modelGRU2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_generator, \n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 8/11 [====================>.........] - ETA: 13s - loss: 1.5213 - categorical_accuracy: 0.3281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning:     `imread` is deprecated!\n",
            "    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 63s 6s/step - loss: 1.4610 - categorical_accuracy: 0.3635 - val_loss: 1.5862 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00001: saving model to model_init_2021-10-2009_02_55.691325/model-00001-1.46099-0.36350-1.58623-0.23000.h5\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 1.0513 - categorical_accuracy: 0.5732 - val_loss: 1.5781 - val_categorical_accuracy: 0.2100\n",
            "\n",
            "Epoch 00002: saving model to model_init_2021-10-2009_02_55.691325/model-00002-1.05132-0.57315-1.57811-0.21000.h5\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.8353 - categorical_accuracy: 0.6712 - val_loss: 1.5616 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00003: saving model to model_init_2021-10-2009_02_55.691325/model-00003-0.83528-0.67119-1.56163-0.23000.h5\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.5933 - categorical_accuracy: 0.7647 - val_loss: 1.5523 - val_categorical_accuracy: 0.3200\n",
            "\n",
            "Epoch 00004: saving model to model_init_2021-10-2009_02_55.691325/model-00004-0.59325-0.76471-1.55235-0.32000.h5\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.4380 - categorical_accuracy: 0.8401 - val_loss: 1.5307 - val_categorical_accuracy: 0.3400\n",
            "\n",
            "Epoch 00005: saving model to model_init_2021-10-2009_02_55.691325/model-00005-0.43800-0.84012-1.53073-0.34000.h5\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.3151 - categorical_accuracy: 0.8854 - val_loss: 1.5338 - val_categorical_accuracy: 0.2900\n",
            "\n",
            "Epoch 00006: saving model to model_init_2021-10-2009_02_55.691325/model-00006-0.31511-0.88537-1.53378-0.29000.h5\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 65s 6s/step - loss: 0.1901 - categorical_accuracy: 0.9351 - val_loss: 1.4920 - val_categorical_accuracy: 0.3400\n",
            "\n",
            "Epoch 00007: saving model to model_init_2021-10-2009_02_55.691325/model-00007-0.19013-0.93514-1.49203-0.34000.h5\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.1386 - categorical_accuracy: 0.9638 - val_loss: 1.6076 - val_categorical_accuracy: 0.2300\n",
            "\n",
            "Epoch 00008: saving model to model_init_2021-10-2009_02_55.691325/model-00008-0.13855-0.96380-1.60760-0.23000.h5\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 63s 6s/step - loss: 0.0933 - categorical_accuracy: 0.9774 - val_loss: 1.5181 - val_categorical_accuracy: 0.3000\n",
            "\n",
            "Epoch 00009: saving model to model_init_2021-10-2009_02_55.691325/model-00009-0.09334-0.97738-1.51811-0.30000.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0683 - categorical_accuracy: 0.9789 - val_loss: 1.4790 - val_categorical_accuracy: 0.3500\n",
            "\n",
            "Epoch 00010: saving model to model_init_2021-10-2009_02_55.691325/model-00010-0.06834-0.97888-1.47896-0.35000.h5\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0300 - categorical_accuracy: 0.9970 - val_loss: 1.5296 - val_categorical_accuracy: 0.3300\n",
            "\n",
            "Epoch 00011: saving model to model_init_2021-10-2009_02_55.691325/model-00011-0.03001-0.99698-1.52956-0.33000.h5\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 61s 6s/step - loss: 0.0332 - categorical_accuracy: 0.9910 - val_loss: 1.4107 - val_categorical_accuracy: 0.3500\n",
            "\n",
            "Epoch 00012: saving model to model_init_2021-10-2009_02_55.691325/model-00012-0.03316-0.99095-1.41066-0.35000.h5\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0269 - categorical_accuracy: 0.9940 - val_loss: 1.3858 - val_categorical_accuracy: 0.4100\n",
            "\n",
            "Epoch 00013: saving model to model_init_2021-10-2009_02_55.691325/model-00013-0.02690-0.99397-1.38578-0.41000.h5\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0150 - categorical_accuracy: 0.9970 - val_loss: 1.2055 - val_categorical_accuracy: 0.5000\n",
            "\n",
            "Epoch 00014: saving model to model_init_2021-10-2009_02_55.691325/model-00014-0.01498-0.99698-1.20552-0.50000.h5\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0070 - categorical_accuracy: 1.0000 - val_loss: 1.1416 - val_categorical_accuracy: 0.6000\n",
            "\n",
            "Epoch 00015: saving model to model_init_2021-10-2009_02_55.691325/model-00015-0.00696-1.00000-1.14156-0.60000.h5\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0075 - categorical_accuracy: 1.0000 - val_loss: 1.1171 - val_categorical_accuracy: 0.5800\n",
            "\n",
            "Epoch 00016: saving model to model_init_2021-10-2009_02_55.691325/model-00016-0.00748-1.00000-1.11713-0.58000.h5\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0044 - categorical_accuracy: 1.0000 - val_loss: 1.1128 - val_categorical_accuracy: 0.5700\n",
            "\n",
            "Epoch 00017: saving model to model_init_2021-10-2009_02_55.691325/model-00017-0.00440-1.00000-1.11280-0.57000.h5\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 1.0755 - val_categorical_accuracy: 0.5600\n",
            "\n",
            "Epoch 00018: saving model to model_init_2021-10-2009_02_55.691325/model-00018-0.00375-1.00000-1.07553-0.56000.h5\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 64s 6s/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 1.0342 - val_categorical_accuracy: 0.5900\n",
            "\n",
            "Epoch 00019: saving model to model_init_2021-10-2009_02_55.691325/model-00019-0.00255-1.00000-1.03418-0.59000.h5\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 1.0297 - val_categorical_accuracy: 0.5400\n",
            "\n",
            "Epoch 00020: saving model to model_init_2021-10-2009_02_55.691325/model-00020-0.00295-1.00000-1.02970-0.54000.h5\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 65s 6s/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.9790 - val_categorical_accuracy: 0.6300\n",
            "\n",
            "Epoch 00021: saving model to model_init_2021-10-2009_02_55.691325/model-00021-0.00183-1.00000-0.97901-0.63000.h5\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 0.9235 - val_categorical_accuracy: 0.7000\n",
            "\n",
            "Epoch 00022: saving model to model_init_2021-10-2009_02_55.691325/model-00022-0.00158-1.00000-0.92352-0.70000.h5\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 68s 7s/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.9384 - val_categorical_accuracy: 0.6700\n",
            "\n",
            "Epoch 00023: saving model to model_init_2021-10-2009_02_55.691325/model-00023-0.00184-1.00000-0.93839-0.67000.h5\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 60s 6s/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.8600 - val_categorical_accuracy: 0.7300\n",
            "\n",
            "Epoch 00024: saving model to model_init_2021-10-2009_02_55.691325/model-00024-0.00130-1.00000-0.85996-0.73000.h5\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.9188 - val_categorical_accuracy: 0.6700\n",
            "\n",
            "Epoch 00025: saving model to model_init_2021-10-2009_02_55.691325/model-00025-0.00149-1.00000-0.91876-0.67000.h5\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.8261 - val_categorical_accuracy: 0.7000\n",
            "\n",
            "Epoch 00026: saving model to model_init_2021-10-2009_02_55.691325/model-00026-0.00139-1.00000-0.82613-0.70000.h5\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 63s 6s/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.9058 - val_categorical_accuracy: 0.6600\n",
            "\n",
            "Epoch 00027: saving model to model_init_2021-10-2009_02_55.691325/model-00027-0.00115-1.00000-0.90584-0.66000.h5\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 8.9030e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9827 - val_categorical_accuracy: 0.6900\n",
            "\n",
            "Epoch 00028: saving model to model_init_2021-10-2009_02_55.691325/model-00028-0.00089-1.00000-0.98272-0.69000.h5\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 62s 6s/step - loss: 8.5642e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9054 - val_categorical_accuracy: 0.6900\n",
            "\n",
            "Epoch 00029: saving model to model_init_2021-10-2009_02_55.691325/model-00029-0.00086-1.00000-0.90540-0.69000.h5\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 59s 6s/step - loss: 9.0987e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9016 - val_categorical_accuracy: 0.6900\n",
            "\n",
            "Epoch 00030: saving model to model_init_2021-10-2009_02_55.691325/model-00030-0.00091-1.00000-0.90161-0.69000.h5\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f863244fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3SI06b9q_7T"
      },
      "source": [
        "**Conclusion** Comparing both the models Conv3D and GRU+Conv2D model . 2nd model of GRU+Conv2D is doing well with from model  \"model-00024-0.00130-1.00000-0.85996-0.73000.h5\" with 100% training accuracy and 73% validation accuracy\n"
      ]
    }
  ]
}